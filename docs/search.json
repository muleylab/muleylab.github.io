[
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Our approach goes beyond the mere identification of crucial genes. We intricately explore the interplay between these genes and their specific anatomical locations, aiming for a comprehensive understanding of their operations within the intricate tapestry of genetic components. Through the utilization of simulations, statistical modeling, artificial intelligence, and network theoretical analysis, we unravel the complex relationships and regulatory mechanisms underlying infectious, autoimmune, neurodegenerative, and neuropsychiatric diseases and disorders.\nBy unraveling these complexities, we gain invaluable insights into the dynamic nature of genes and their profound impact on the survival and adaptability of living organisms. This knowledge forms the foundation of our research, empowering us to develop novel therapeutic strategies and interventions that precisely target these genes and their associated pathways. Our ultimate goal is to make transformative discoveries that pave the way for personalized treatments, improved patient outcomes, and a deeper understanding of the intricate mechanisms governing health and disease. The frontiers areas that we have been working on are given below."
  },
  {
    "objectID": "research.html#gene-expression-and-regulation",
    "href": "research.html#gene-expression-and-regulation",
    "title": "Research",
    "section": "Gene expression and regulation",
    "text": "Gene expression and regulation\nOur group studies how the body makes proteins from the instructions in our DNA (Muley and Pathania, 2017). This process is called gene expression and it’s important for keeping our cells healthy. We look at how genes are turned on and off and how that can change how cells work (Muley and Koenig, 2022). We’re especially interested in ways that this process can go wrong and cause problems like aging and diseases of the brain.\n\n\n\n\n \n\n\nFigure 1: Upstream region of a gene bounded by regulatory factors dictating its expression (left panel). Gene expression profiles of tissues, cell types, and time series (toy example)"
  },
  {
    "objectID": "research.html#intercellular-protein-protein-interaction-networks",
    "href": "research.html#intercellular-protein-protein-interaction-networks",
    "title": "Research",
    "section": "Intercellular protein-protein interaction networks",
    "text": "Intercellular protein-protein interaction networks\nProtein-protein interaction (PPI) networks is a scientific field that looks at how proteins in a cell interact with each other. We use computational tools and methods to study and map out these interactions to understand how they contribute to the overall function of the cell (Muley and Acharya, 2012, Muley, Ph.D. thesis, 2012). This knowledge can be used to develop new drugs, identify new drug targets, and improve our understanding of diseases and the functioning of cells.\n\n\n\nFigure 2: Protein-protein interactions subnetworks associated with cell surface regulates bacterial cell division\n\n\nIn addition to studying interactions within a cell, we are also interested in understanding protein interactions between cells. These interactions play a critical role in various cellular processes, including cell communication, growth, and differentiation and are involved in both normal and disease processes. Understanding intercellular interactions has potential applications in medicine, such as developing new drugs and therapies that target these interactions."
  },
  {
    "objectID": "research.html#functional-and-developmental-neurobiology",
    "href": "research.html#functional-and-developmental-neurobiology",
    "title": "Research",
    "section": "Functional and Developmental neurobiology",
    "text": "Functional and Developmental neurobiology\nDevelopmental neurobiology is a field of study that focuses on the development and maturation of the nervous system. It encompasses the cellular and molecular mechanisms that underlie the formation and function of the brain and spinal cord.\nThe cerebrum is the largest part of the brain and is responsible for many functions such as consciousness, movement, sensation, perception, reasoning, and memory. The cerebrum develops from a structure called the telencephalon, which is a part of the embryonic brain. During embryonic development, the cerebrum is formed from a structure called the neural plate, which is a sheet of cells that folds and develops into the three primary brain vesicles: the prosencephalon, the mesencephalon, and the rhombencephalon. The prosencephalon develops into the telencephalon, which gives rise to the cerebrum.\n\n\n\n\n \n\n\nFigure 3: Brain and its extensions throughout body (left panel). A closuer look at the the hypothalamus and its connection with the pituitary gland (right panel), which together plays a critical role in regulating many of the body’s physiological processes.\n\n\nLineage specific divergence refers to the process by which different species or lineages of organisms evolve different characteristics or features. In the case of the cerebrum, different lineages of animals, such as birds and mammals, have developed different characteristics in their cerebrum despite having a similar developmental origin. The molecular pathways that control cerebrum development in birds and mammals diverge, leading to the formation of distinct structures and functions. This divergence is thought to have occurred as a result of different selective pressures and adaptations to different environments. We have identified molecular pathways that are relevant to these differences, and we have provided evidence for the possible origins of neuropsychiatric diseases due to impaired cerebrum development (Muley et.al., 2020). We are currently developing a computational framework to address some long-standing questions in biology, such as the spatiotemporal map of protein-protein interactions that connect brain-driven processes to various organs in the body during development and the formation of neural circuits."
  },
  {
    "objectID": "research.html#evolutionary-biology",
    "href": "research.html#evolutionary-biology",
    "title": "Research",
    "section": "Evolutionary biology",
    "text": "Evolutionary biology\nEvolutionary biology is the study of how living things have changed and developed over time. It uses information from different areas of science to understand how life on Earth began and how it has changed. The main idea is that all living things come from a common ancestor and have grown and changed through natural processes.\n\n\n\nFigure 4: The distribution of about PDZ domain containing proteins across 1,476 microbial genomes (left panel), their classification (middle panel), and the evolutionary origin (right)\n\n\nOur goal is to investigate the distribution and evolution of protein domains, such as the PDZ domain, across different genomes. The PDZ domain is particularly challenging to study due to its high sequence divergence and frequent combination with other domains in proteins (Figure 4). Our previous research on PDZ domain-containing proteins from over 1400 microbial genomes led us to propose a link between their evolution and the development of multicellularity and organismal complexity (Muley et.al., 2019). We also assigned potential functions to many previously uncharacterized protein families, and proposed their last universal common ancestor. Currently, we are expanding our research to include PDZ domains from animals, plants and viruses and to the highly ubiquitous haloacid domain in over 17,000 genomes across the three domains of life and viruses. These domains play critical roles in regulating important signaling pathways involved in embryonic development, synaptic signaling, and metabolism relevant to human health."
  },
  {
    "objectID": "research.html#systems-biology-of-diseases",
    "href": "research.html#systems-biology-of-diseases",
    "title": "Research",
    "section": "Systems biology of diseases",
    "text": "Systems biology of diseases\nDespite significant progress in the field of biology, the lack of early diagnostic markers or effective treatments for numerous debilitating diseases and infections remains a significant challenge for society. These include neuropsychiatric, neurodegenerative, autoimmune, as well as viral infections such as genital herpes, hepatitis, mononucleosis, papillomavirus infection, AIDS, and COVID-19.\n\n\n\n\n \n\n\nFigure 5: Impaired protein-protein interactions encoded by genes in a red color subnetwork during cerebrum development may lead to neuropsychirtic disorders (left panel). PPI network of autism spectrucm disorder associated proteins identified by integrative analysis of transcriptomic and protein-protein interaction data (right panel)\n\n\nTo address this challenge, we have developed methods for large-scale or meta-analysis of gene expression data, as well as next-generation tissue and single-cell RNA-Seq data, using systems biology of disease approach. This approach aims to understand the underlying mechanisms of diseases using computational methods and data from multiple sources, and to identify the complex interactions between genes, proteins, and other biomolecules that contribute to disease development and progression. By taking a systems-level approach, we are able to identify new insights and connections that might not have been apparent from traditional reductionist methods, leading to a better understanding of the underlying causes of diseases and new strategies for diagnosis, treatment, and prevention."
  },
  {
    "objectID": "posts/mimbgrn/index.html",
    "href": "posts/mimbgrn/index.html",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "",
    "text": "Install tensorflow R package\n\n\ninstall.packages(\"tensorflow\")\n\n\nTensorFlow uses Python programming language. Therefore, R should be configured to use Python\nIf Python is already installed on computer then use following commands to configure R to use Python installation.\n\n\nlibrary(reticulate)\npath_to_python <- \"/usr/local/bin/python3\" \nvirtualenv_create(\"r-reticulate\", python = path_to_python)\n\nHere, we just provide a path to python executable (in this case, it is Python version 3). On macOS or Unix/Linux systems python”s default location is /usr/local/bin/ folder. However, users should confirm the correct path on computers.\n\nIf Python is not installed on computer then use following commands to install Python and then configure R.\n\n\nlibrary(reticulate)\npath_to_python <- \"/usr/local/bin/python3\" \nvirtualenv_create(\"r-reticulate\", python = path_to_python)\n\n\nNext, use the install_tensorflow() function from the tensorflow package to install TensorFlow.\n\n\nlibrary(tensorflow)\ninstall_tensorflow(envname = \"r-reticulate\")\n\n\nUse the install_keras() function from the keras package to install TensorFlow along with some commonly used packages such as “scipy” and “tensorflow-datasets” as shown below.\n\n\ninstall.packages(\"keras\")\nlibrary(keras)\ninstall_keras(envname = \"r-reticulate\")\n\n\nTo confirm that the installation was successful, run the following command, which should return tf.Tensor(b”Hello Tensorflow!“, shape=(), dtype=string). If not then try “install_tensorflow()” command again.\n\n\nlibrary(tensorflow)\ntf$constant(\"Hello Tensorflow!\")\n\n\nInstall following packages to facilitate data handling and analysis.\n\n\ninstall.packages(c(\"readr\", \"tibble\", \"caret\", \"verification\"))"
  },
  {
    "objectID": "posts/mimbgrn/index.html#data-requirements",
    "href": "posts/mimbgrn/index.html#data-requirements",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "Data requirements",
    "text": "Data requirements\n\nDownload Supplementary Data 1 from the DREAM5 network inference challenge publication (https://doi.org/10.1038/nmeth.2016) and unzip it in your current working directory. Go to nealy created “DREAM5_network_inference_challenge” directory.\nThe required data for Escherichia coli is present in the “Network3” folder and its sub-folders. Copy four files listed below from these sub-folders into your current working directory to proceed with the analysis..\nnet3_expression_data.tsv: This file contains the expression profile data.\nnet3_transcription_factors.tsv: This file contains the list of transcription factors.\nDREAM5_NetworkInference_GoldStandard_Network3.tsv: This file contains the gold standard data, which includes both regulatory (positive examples) and non-regulatory (negative examples) TF-gene pairs.\nnet3_gene_ids.tsv: This file serves as a mapping between the anonymous gene codes used in other files and the original gene names."
  },
  {
    "objectID": "posts/mimbgrn/index.html#load-r-libraries",
    "href": "posts/mimbgrn/index.html#load-r-libraries",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "Load R libraries",
    "text": "Load R libraries\n\n\n\n\nlibrary(magrittr)\nlibrary(keras)\nlibrary(tensorflow)\n\n\nSet a random odd number as a seed in the set.seed function to reproduce the results of this workflow.\n\n\nset.seed(1979)"
  },
  {
    "objectID": "posts/mimbgrn/index.html#data-preparation-and-exploration",
    "href": "posts/mimbgrn/index.html#data-preparation-and-exploration",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "Data preparation and exploration",
    "text": "Data preparation and exploration\n\nImport the gene expression data and store in a exp object and do a routine check up as shown below.\n\n\nexp <- read.table(\"net3_expression_data.tsv\", header = T)\nexp <- t(exp)\ndim(exp)\nexp[1:5,1:5]\n\n\nPlot distribution of expression values to check trends in the data.\n\n\n# plot\nhist(exp, 100, col = \"darkgrey\", border = \"white\", \n     xlab = \"Expression intensity\", main = \"Gene expression\")\n\n# export plot to pdf file in the current directory\npdf(file = \"DeepLearning_Figure1.pdf\", \n    width = 5, height = 5, pointsize = 10, useDingbats = FALSE)\nhist(exp, 100, col = \"darkgrey\", border = \"white\", \n     xlab = \"Expression intensity\", main = \"Gene expression\")\ndev.off()\n\n\nLoad the gold standard data.\n\n\ngold <- readr::read_table(\"DREAM5_NetworkInference_GoldStandard_Network3.tsv\",\n                          col_names = F)\ngold\n\nIn the gold object, the first two columns respectively list the TFs and genes, while the third column contains binary labels. A value of 1 in the label column indicates that experimental evidence exists for the regulation of the gene in column 2 by the transcription factor in column 1, while a value of 0 indicates that there is no known regulatory interaction between them.\n\nMake expression and gold standard data compatible.\n\n\ngold <- gold[gold$X1 %in% rownames(exp) & gold$X2 %in% rownames(exp), ]\ntable(gold$X3)\n\n\nThe gold standard data is imbalanced, with 2066 regulatory pairs and 150,214 non-regulatory pairs. Lets down-sample majority class examples randomly so that they are two times more than that of regulatory pairs.\n\n\nkeep_indices <- c(which(gold$X3==1), \n                  sample(which(gold$X3==0), size = sum(gold$X3)*2))\ngold <- gold[keep_indices,]\ntable(gold$X3)\n\n\nIn the next step, we create a feature table containing raw expression data for TF-gene pair, and we will manually create a feature which represent pearson correlation coefficients between expression profiles of transcription factors and genes. This correlation measure is a conventional approach for engineering features from raw data. The resulting correlation coefficients are added as a new column named “pcc” within the data.frame. Subsequently, labels are appended as the last column of the data.frame. The first two columns of the data.frame represent the names of the TF and gene, respectively. The remaining columns contain the expression values for the TF and gene, followed by the calculated PCC values between their expression values, and finally the gold standard label. To facilitate further analysis, the column names that correspond to the expression values and PCC are stored in the “featurenames” object, as they will serve as features for subsequent processing.\n\nThe code snippet below demonstrates these steps:\n\ninputdata <- data.frame(tf = gold$X1, gene = gold$X2, \n                        exp[gold$X1,], exp[gold$X2,])\ninputdata$pcc <- sapply(seq.int(dim(gold)[1]), function(i) \n                        cor(exp[gold$X1[i],], exp[gold$X2[i],]))\ninputdata$class <- gold$X3\n\ninputdata <- tibble::as_tibble(inputdata)\n\nfeaturenames <- colnames(inputdata) %>% setdiff(\"class\")  %>% \n  setdiff(\"tf\") %>% setdiff(\"gene\")\n\n\nLets plot feature data points for regulatory and non-regulatory pairs to see if there are any visible trend which can distinguish them based on our data.\n\n\nh1 <- hist(as.matrix(inputdata[inputdata$class==\"1\",featurenames]), \n           breaks = 100, plot = FALSE)\nh2 <- hist(as.matrix(inputdata[inputdata$class==\"0\",featurenames]), \n           breaks = 100, plot = FALSE)\n\npdf(file = \"DeepLearning_Figure2.pdf\", \n    width = 5, height = 5, pointsize = 10, useDingbats = FALSE)\nplot(h2, col = rgb(0,0,1,0.4), freq = FALSE, \n     xlab = \"Expression intensity\", \n     main = \"Distribution of feature values for training data\")\nplot(h1, xaxt = \"n\", yaxt = \"n\", col = rgb(1,0,0,0.4), \n     freq = FALSE, add = TRUE)\ndev.off()\n\n\nThe following code implements division of gold standard data into training, validation and test datasets in 80:10:10 proportions. The proportions are subjective.\n\n\nindices <- nrow(inputdata) %>% sample.int(., ceiling( . * 0.8))\ntraindata <- inputdata[indices, ]\ntestdata <- inputdata[-indices, ]\nindices <- nrow(testdata) %>% sample.int(., ceiling( . * 0.5))\nvaldata <- testdata[-indices, ]\ntestdata <- testdata[indices, ]\ntable(traindata$class)\ntable(valdata$class)\ntable(testdata$class)"
  },
  {
    "objectID": "posts/mimbgrn/index.html#defining-deep-learning-model-architecture",
    "href": "posts/mimbgrn/index.html#defining-deep-learning-model-architecture",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "Defining deep learning model architecture",
    "text": "Defining deep learning model architecture\n\nLets create a sequential deep neural network (DNN) using the keras_model_sequential() function from the Keras library. We then add two dense layers using the layer_dense() function. The input layer is defined with the input_shape parameter, which needs to be equal to the total number of features in the input data or represents the shape of the features. Next, the single hidden layer contains 806 neurons and applies the “relu” activation function to introduce non-linearity in the layer”s output. The second layer_dense() function adds another fully connected layer with a single output unit. This output layer computes a weighted sum of the inputs from the previous layer feeds and applies the sigmoid activation function to produce a probability value between 0 and 1, indicating the likelihood that the input corresponds to the positive class (regulatory pairs, in this case) based on input features.\nThe code below sets a random seed for tensorflow using set_random_seed function. Then, creates a sequential deep neural network (DNN) using the keras_model_sequential() function from the Keras library. The DNN model has a simple architecture with input layer which feeds feature matrix and labels to fully connected layers hidden layer with “relu” activation, and a another fully connected output layer with “sigmoid” activation to produces a single probability value for each training example of being regulatory pair. The summary function shows an overview of the model”s architecture.\n\n\nset_random_seed(1979)\n\nmodel <- keras_model_sequential(\n  input_shape = c(length(featurenames))) %>%\n  layer_dense(units = 806, activation = \"relu\") %>%\n  layer_dense(units = 1, activation = \"sigmoid\")\n\nsummary(model)"
  },
  {
    "objectID": "posts/mimbgrn/index.html#defining-model-compilation-parameters",
    "href": "posts/mimbgrn/index.html#defining-model-compilation-parameters",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "Defining Model Compilation Parameters",
    "text": "Defining Model Compilation Parameters\n\nTo configure the learning process, the model”s compilation parameters are specified using the following code. The compile() function configures the model. The optimizer_adam() function is a widely used optimization algorithm that computes adaptive learning rates for each parameter based on the moment estimates of the gradient and past gradients and helps neural network to converge faster. The loss function measures the difference between predicted and actual values. The “binary_crossentropy” loss function is commonly used for binary classification tasks. IThe “accuracy” metric is used to calculate the percentage of correctly predicted labels by the model. Accuracy metric is fine for prototyping DNN, but use more reliable metrics for practical application.\n\n\nmodel %>% compile(optimizer = optimizer_adam(),\n loss = \"binary_crossentropy\",\n metrics = c(\"accuracy\"))"
  },
  {
    "objectID": "posts/mimbgrn/index.html#training-deep-learning-model",
    "href": "posts/mimbgrn/index.html#training-deep-learning-model",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "Training deep learning model",
    "text": "Training deep learning model\n\nThe following code chunk fits the DNN model to the training data and validates its performance using a validation dataset by using the fit() function:\n\n\nhistory <- model %>% fit(as.matrix(traindata[,featurenames]), \n                         traindata$class,\n                         epochs=100, batch_size = 64,\n                         validation_data = list(as.matrix(valdata[,featurenames]), \n                                                valdata$class))"
  },
  {
    "objectID": "posts/mimbgrn/index.html#estimating-the-accuracy-of-deep-learning-model",
    "href": "posts/mimbgrn/index.html#estimating-the-accuracy-of-deep-learning-model",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "Estimating the accuracy of deep learning model",
    "text": "Estimating the accuracy of deep learning model\n\nUse evaluate function to compute accuracy and loss function over all epochs as shown below. The code plot(history) generates a plot of the training and validation loss and accuracy over the course of the training process. This visualization can help identify trends or patterns in the performance of the model.\n\n\nprint(history)\nevaluate(model, x = as.matrix(traindata[,featurenames]), y = traindata$class)\nevaluate(model, x = as.matrix(valdata[,featurenames]), y = valdata$class)\nplot(history)\n\n\nYou can customize plots using following code. For instance,\n\n\npdf(file = \"DeepLearning_Figure3.pdf\",\n    width = 7, height = 4, pointsize = 10, useDingbats = FALSE)\n\npar(mfrow = c(1,2), cex = 0.8)\n\nmaxLoss <- max(c(history$metrics$loss, history$metrics$val_loss))\n\nplot(history$metrics$loss, main=\"Model Loss\", xlab = \"Epoch\", ylab=\"Loss\", \n     xlim = c(0, length(history$metrics$loss)), ylim = c(0, maxLoss),\n     col=\"red2\", type=\"b\",lwd=1)\nlines(history$metrics$val_loss, col=\"steelblue1\", type=\"b\",lwd=1)\nlegend(\"topright\", c(\"Training\",\"Validation\"), col=c(\"red2\", \"steelblue1\"), \n       lty=c(1,1), bty = \"n\")\n\nplot(history$metrics$accuracy, col=\"red2\", type=\"b\",lwd=1, \n     main=\"Model Accuracy\", xlab = \"Epoch\", ylab=\"Accuracy\", \n     xlim = c(0, length(history$metrics$accuracy)), ylim = c(0, 1))\nlines(history$metrics$val_accuracy, col=\"steelblue1\", type=\"b\",lwd=1)\nabline(h = 0.5, col = \"grey\", lty = 3)\ndev.off()"
  },
  {
    "objectID": "posts/mimbgrn/index.html#predicting-labels-for-unlabelled-pairs-of-transcription-factors-and-genes.",
    "href": "posts/mimbgrn/index.html#predicting-labels-for-unlabelled-pairs-of-transcription-factors-and-genes.",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "Predicting labels for unlabelled pairs of transcription factors and genes.",
    "text": "Predicting labels for unlabelled pairs of transcription factors and genes.\n\nThe code provided below utilizes our model to predict the probabilities of outcomes for the test dataset, which is unlabelled and completely unknown to the model. This prediction is achieved by using the predict() function, and the resulting probabilities are stored in the variable predprob for further utilization.\n\n\npredprob <- model %>% predict(as.matrix(testdata[,featurenames]))\n\n\nTo evaluate the performance of the DNN model on the test data and compare it with the training and validation data, the confusionMatrix() function from the caret package can be used. This function takes the predicted class probabilities in a binary format, specifically using a threshold of 0.5 or above (i.e., as.numeric(predprob > 0.5)), along with the true class labels. It then generates a table containing various important performance measures as shown below.\n\n\nf1 <- function(indata, truelabels){\n  res <-  model %>% predict(as.matrix(indata[,featurenames]))\n  res <- as.numeric(res>0.5)\n  res <- factor(res, c(1,0))\n  caret::confusionMatrix(res, factor(truelabels, c(1,0)))\n}\n\ntrainAccuracy <- f1(traindata, traindata$class)\nvalidationAccuracy <- f1(valdata, valdata$class)\ntestAccuracy <-f1(testdata, testdata$class)\n\nperformance <- round(t(as.data.frame(rbind(t(trainAccuracy$byClass), \n                                           t(validationAccuracy$byClass), \n                                           t(testAccuracy$byClass)))),3)\ncolnames(performance) <- c(\"Traning\", \"Validation\", \"Test\")\n\nperformance\n\n\nBiologists may prefer to use a higher probability cutoff to avoid false positive results, even if it means predicting fewer regulatory interactions. The ROC curve is a perfect instrument which shows how the classifier”s performance changes at different threshold settings for guidance. In the following code, roc.plot function from verification package is used to plot ROC curve\n\n\npdf(file = \"DeepLearning_Figure4.pdf\",\n    width = 5, height = 5, pointsize = 12, useDingbats = FALSE)\n\nverification::roc.plot(testdata$class, predprob, \n                       ylab = \"True Positive Rate\", \n                       xlab = \"False Positive Rate\")\nabline(v = 0.5596, col = \"red2\", lty = 3)\nabline(h = 0.0509, col = \"steelblue1\", lty = 3)\n\ndev.off()\n\n\nThe following code shows that how to save the model for future use, and we also save performance table, expression and gold standard data which we all need to reproduce all the results or to make new better deep learning model.\n\n\nsave_model_hdf5(model, \"EcoliRegModel.h5\")\nsave(exp, performance, gold, history, file = \"EcoliRegModel.RData\")\n\nThe save_model_hdf5() function saves the model in the Hierarchical Data Format version 5 (HDF5) file format. HDF5 is a file format designed to store and organize large amounts of numerical data. It is a binary file format that can store the model architecture, weights, optimizer state, and any other information related to the model."
  },
  {
    "objectID": "posts/mimbgrn/index.html#predicting-genome-wide-regulatory-interactions",
    "href": "posts/mimbgrn/index.html#predicting-genome-wide-regulatory-interactions",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "Predicting genome-wide regulatory interactions",
    "text": "Predicting genome-wide regulatory interactions\n\nIn this section, we will demonstrate how to evaluate the pairwise combinations of transcription factors (TFs) and genes in Escherichia coli using our model. We will assess the probability of these pairs being potential regulatory pairs. It”s important to note that the total number of TF-gene pairs for Escherichia coli exceeds a million and a half, and in higher organisms, the number is even greater. Consequently, most computers may struggle to handle the feature data for all these pairs, potentially causing crashes. Therefore, the following code is specifically provided for users who do not possess high-end computational resources. For those with ample computational resources, I recommend referring to the code provided in Note 13. As these codes can be used across different sessions of RStudio, they assume that the computer or RStudio has been restarted and the same directory has been set (can be verified using the getwd() function).\n\n\nlibrary(magrittr)\nlibrary(keras)\nlibrary(tensorflow)\n\nset.seed(1979)\n\n\nmodel <- load_model_hdf5(\"EcoliRegModel.h5\")\n\n# import expression data file\nexp <- t(read.table(\"net3_expression_data.tsv\", header = T))\n\n# import original gene names mapping \ngenenames <- read.table(\"net3_gene_ids.tsv\", header = F)\ngenes <- genenames$V2; names(genes) <- genenames$V1\n\n# import list of all transcription factors of Escherichia coli\n# tfs <- names(genes)[genes %in% c(\"gadX\", \"flhC\", \"flhD\",\"dnaA\")] # trail run\ntfs <- read.table(\"net3_transcription_factors.tsv\", header = F)$V1\n\nlength(tfs)*nrow(exp)\n\n\npredictions <- NULL\n\nfor(i in tfs){\n  \n  tfdata <-data.frame(tf = i, gene = rownames(exp), \n                      tfname = genes[i],\n                      genename = genes[rownames(exp)])\n  tfdata <- tibble::as_tibble(tfdata[tfdata$tf != tfdata$gene,])\n  \n  inpreddata <- cbind(exp[tfdata$tf,], exp[tfdata$gene,])\n  inpreddata <- cbind(inpreddata, \n                      sapply(seq.int(dim(tfdata)[1]), \n                             function(i) \n                               cor(exp[tfdata$tf[i],], \n                                   exp[tfdata$gene[i],])))\n  \n  tfdata$probability <- (model %>% predict(inpreddata))[,1]\n  \n  predictions <- rbind(predictions, tfdata[tfdata$probability>0.5,])\n  \n}\n\npredictions <- predictions[rev(order(predictions$probability)),]\npredictions\n\n\nOur model predicted only 80,225 as regulatory out of 1,506,674 TF-gene pairs. There are number of sophisticated ways to evaluate the predicted GRN. Here, however, we will quickly select few TF-gene pairs with high probability of being regulatory, and will study them. Escherichi coli has many acid inducible systems which protect cells against acid stress to pH 2 or below. Of them, the glutamate depending system is the most effect and relies on two glutamate decarboxylases (GadA and GadB) combined with a putative glutamate:gamma-aminobutyric acid antiporter (GadC). According to our predictions, it appears to be regluated by OsmE, which is osmolarity inducible factor, however, there is no information exists that it regulates glutamate-dependant acid resistance system. though functionally it would make sense. The GadX is a known regulator of the acid resistance system. Also, master transcription factors associated with flagella biosynthesis and chemotaxis were among the highly ranked TF-gene pairs. So, lets check target genes of GadX, FlhC, and FlhD transcription factors.\n\n\npredictions[predictions$tfname==\"gadX\",]\npredictions[predictions$tfname==\"flhC\",]\npredictions[predictions$tfname==\"flhD\",]\n\nOur results suggests that GadX may regulate 16 genes at the probability cutoff of 0.5 or above, and of 16, five genes i.e. gadA, gadE gadB, gadC and gadW belong to glutamate dependant acid protection system, confirming the accuracy of our prediction system. Likewise, FlhC and FlhD regulates a large number of genes involved in flagellar assembly and chemotaxis reassuring our prediction system. The overlap of their target genes is 652, which is highly expected. One of the problem of deep learning algorithm is that they can memorize the training dataset and many of the predictions could be part of training or validation dataset. Therefore, lets remove all predictions that were part of the training, and again cross-check the results using following command. As you can see, there are still many predictions which were novel, and make perfect sense at functional level.\n\npredictions[!paste0(predictions$tf,predictions$gene) %in%  \n              paste0(inputdata$tf[inputdata$class==1], \n                     inputdata$gene[inputdata$class==1]),] \n\n\nTo export results from prediction object to a tabular, csv or excel file, use following code. The third command requires writexl R package which should be installed using install.packages function. Likewise, you can also export the performance table.\n\n\nwrite.table(predictions, file = \"grnPredictionsEcoli.txt\", \n            col.names = T, row.names = F, quote = F, sep = \"\\t\")\nwrite.csv(predictions, file = \"grnPredictionsEcoli.csv\", row.names = F)\nwritexl::write_xlsx(list(Table1 = predictions), \n                    path = \"grnPredictionsEcoli.xlsx\", col_names = T, )"
  },
  {
    "objectID": "posts/mimbgrn/index.html#handiling-imbalanced-gold-standard-data",
    "href": "posts/mimbgrn/index.html#handiling-imbalanced-gold-standard-data",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "Handiling imbalanced gold standard data",
    "text": "Handiling imbalanced gold standard data\n\nImbalanced data is a common challenge in biology, making training deep learning models tricky [@golddeeplearning]. R packages such as caret, ROSE, and smote [@caret; @rose; @smote] are popular resources for addressing imbalanced data. While the smotefamily package utilizes the SMOTE algorithm to generate synthetic samples of the minority class. Another approach is to down-size the majority class examples to make them compatible with minority class. I have used this approach for our problem. Also, I often prefer the class weight approach. In the provided code snippet, the “class_weight” parameter is used during model training for binary classification. By calculating class weights based on the class distribution in the training data, and passing them as the “class_weight” argument in the fit function, you can assign higher weights to the minority class and lower weights to the majority class. This enables the model to effectively handle class imbalance during optimization, prioritizing the minority class samples for better learning outcomes."
  },
  {
    "objectID": "posts/mimbgrn/index.html#increasing-generalization-and-depth-of-dnn",
    "href": "posts/mimbgrn/index.html#increasing-generalization-and-depth-of-dnn",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "Increasing generalization and depth of DNN",
    "text": "Increasing generalization and depth of DNN\n\nThe number of layers and neurons (units) in a neural network can be adjusted to enhance its learning capacity [@layersneurons]. However, there is no definitive rule on how many layers and neurons a network should have for a given dataset. If the data is linearly separable, multiple hidden layers may not be necessary. It is generally recommended to keep the number of hidden layers as minimal as possible. The number of neurons in a layer can be determined based on the shape of your training data. Typically, the number of neurons in a layer is equal to the number of features (columns) in your data. Some network configurations add an additional node for a bias term. It is crucial to maintain a low number of nodes to ensure the network”s ability to generalize well. Having an excessive number of nodes may cause the network to perfectly recall the training set but perform poorly on new, unseen samples. The following code shows how to include more layer but there are numbe of different ways one can add layers and decide on number of neurons. Usually in each successive layers, the number of neurons are decreased."
  },
  {
    "objectID": "posts/mimbgrn/index.html#performance-measures",
    "href": "posts/mimbgrn/index.html#performance-measures",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "Performance measures",
    "text": "Performance measures\n\nAccuracy can be misleading when dealing with imbalanced datasets as it does not account for class imbalance. Recall and precision metrics are often preferred over accuracy in most scenarios, especially when the cost of false positives and false negatives differs significantly. Recall measures the proportion of true positive cases correctly identified, while precision measures the proportion of correctly identified positive cases. These metrics provide a more comprehensive understanding of the model”s performance, especially when the focus is on correctly identifying specific classes or minimizing false positives/negatives. These metrics could be set in with the complie() function as shown below. Remove comment (#) character to include the metric for training."
  },
  {
    "objectID": "posts/mimbgrn/index.html#an-alternative-code-for-prediction-of-grn-on-high-end-computational-resources.",
    "href": "posts/mimbgrn/index.html#an-alternative-code-for-prediction-of-grn-on-high-end-computational-resources.",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "An alternative code for prediction of GRN on high-end computational resources.",
    "text": "An alternative code for prediction of GRN on high-end computational resources.\n\nlibrary(magrittr)\nlibrary(keras)\nlibrary(tensorflow)\n\nset.seed(1979)\n\n\nmodel <- load_model_hdf5(\"EcoliRegModel.h5\")\n\n# import expression data file\nexp <- t(read.table(\"net3_expression_data.tsv\", header = T))\n\n# import original gene names mapping \ngenenames <- read.table(\"net3_gene_ids.tsv\", header = F)\ngenes <- genenames$V2; names(genes) <- genenames$V1\n\n# import list of all transcription factors of Escherichia coli\ntfs <- read.table(\"net3_transcription_factors.tsv\", header = F)$V1\n\n# create all possible pairs between tanscription factors and genes\n\npredictions <- expand.grid(tfs,  rownames(exp), stringsAsFactors = FALSE)\npredictions <- tibble::as_tibble(all_pairs[predictions$Var1 != predictions$Var2,])\n\n# add original gene names\n\npredictions$tfname <- genes[predictions$Var1]\npredictions$genename <- genes[predictions$Var2]\n\n# create feature table\ninpreddata <- cbind(exp[predictions$Var1,], exp[predictions$Var2,])\ninpreddata$pcc  <- sapply(seq.int(dim(predictions)[1]), \n                          function(i) cor(exp[predictions$Var1[i],], \n                                          exp[predictions$Var2[i],])))\n\n# predict regulatory pairs\npredictions$probability <- (model %>% predict(inpreddata))[,1]\npredictions <- predictions[predictions$probability>0.5,]\npredictions <- predictions[rev(order(predictions$probability)),]\npredictions"
  },
  {
    "objectID": "posts/mimbgrn/index.html#controlling-dnn-model-training-by-callback-functions",
    "href": "posts/mimbgrn/index.html#controlling-dnn-model-training-by-callback-functions",
    "title": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R",
    "section": "Controlling DNN model training by Callback functions",
    "text": "Controlling DNN model training by Callback functions\nEarlyStopping Callback: This callback monitors the validation loss and stops the training if the validation loss does not improve after a certain number of epochs (defined by the “patience” parameter).\n\nearly_stopping <- callback_early_stopping(monitor = \"val_loss\", patience = 3)\n\nModelCheckpoint Callback: This callback saves the model weights to a file (“best_model.h5”) whenever the validation accuracy improves. By setting “save_best_only” to True, it only saves the best model based on the monitored metric..\n\nmodel_checkpoint <- callback_model_checkpoint(filepath = \"best_model.h5\", \n                                              monitor = \"val_accuracy\", \n                                              save_best_only = TRUE)\n\nReduceLROnPlateau Callback: This callback reduces the learning rate when the validation loss plateaus. The learning rate is multiplied by the “factor” parameter, and “patience” determines the number of epochs to wait before reducing the learning rate.\n\nreduce_lr <- callback_reduce_lr_on_plateau(monitor = \"val_loss\", \n                                           factor = 0.1, patience = 2)\n\nTensorBoard: This callback enables logging for TensorBoard, which is a visualization tool for monitoring the training process. It creates logs that can be visualized using TensorBoard.\n\ntensorboard <- callback_tensorboard(log_dir = \"logs\")\n\nOnce callback functions are defined they can be incorporated during training as shown below for early_stopping and reduce_lr callback functions, but you can have as many functions as you want.\n\nhistory <- model %>% fit(as.matrix(traindata[,featurenames]), traindata$class,\n                           epochs=40, batch_size = 50, validation_split=0.2,\n                           callbacks = list(early_stopping, reduce_lr))"
  },
  {
    "objectID": "positions.html",
    "href": "positions.html",
    "title": "Join us",
    "section": "",
    "text": "Research Opportunities in Bioinformatics, Computational biology, Data science, and AI\nJoin our cutting-edge research lab that uses bioinformatics, computational biology, and machine learning to investigate long-standing questions in medicine, agriculture, and life sciences with the goal of benefiting humankind. Our team of experienced scientists offers opportunities for Ph.D. students, masters thesis students, bachelors thesis students, interns, and paid research trainees.\n\n\nOpportunities include\n\nConducting cutting-edge research using AI and bioinformatics techniques\nProfessional growth and career development in a dynamic and supportive research environment\nOpportunity to work abroad under the supervision of an experienced researcher\nHands-on experience in laboratory techniques and research methods\nPublish findings in peer-reviewed journals and present at conferences\n\n\n\nTo Apply:\nPlease send your CV or express your interest through at vijay dot muley at gmail dot com\nJoin us in making a difference in the fields of medicine, agriculture, and life sciences."
  },
  {
    "objectID": "team.html",
    "href": "team.html",
    "title": "Members",
    "section": "",
    "text": "About me\n muleylab at gmail dot com"
  },
  {
    "objectID": "bsVijay.html",
    "href": "bsVijay.html",
    "title": "Biographical Sketch",
    "section": "",
    "text": "I received my B.Sc. degree in Chemistry, Zoology, and Fishery Science in 2000 and my M.Sc. in Biotechnology in 2002 from Dr. Babasaheb Ambedkar Marathwada University in Aurangabad, India. In 2005, I completed my second M.Sc. degree in Bioinformatics at the University of Pune in Pune, India. In 2012, I obtained my Ph.D. degree in Bioinformatics from the Computational and Functional Genomics Laboratory at the Centre for Fingerprinting and DNA Diagnostics (CDFD) in Hyderabad, India, under the supervision of Dr. Akash Ranjan.\nIn April 2012, I joined the Indian Institute of Science Education and Research (IISER) in Pune, India as a postdoctoral scientist in Dr. Sanjeev Galande’s laboratory, where I worked on animal evolution, embryonic development, and epigenetic regulation. In October 2013, I moved to Jena, Germany as a staff scientist and worked on mathematical modeling of gene expression and regulation in breast cancers at the Leibniz Institute for Natural Product Research and Infection Biology, in the Network Modelling group headed by Professor Rainer Koenig. In February 2016, I was appointed as an assistant professor on a permanent basis at the Central University of Punjab in Bathinda, India in the Centre for Computational Sciences. However, I resigned from the position after a while and decided to work as a full-time researcher at University College Cork, National University of Ireland in Cork City, Ireland from September 2017. There, I worked on IFN-gamma and TNF-alpha signaling pathways involved in immune responses with Dr. Ken Nally. In April 2018, I was invited to join the Institute of Neurobiology at the National Autonomous University of Mexico (UNAM) in Queretaro, Mexico, as an assistant professor and senior scientist in the neural laboratory of neural development. At UNAM, I worked on various research projects in the field of neurobiology and studied the molecular basis of embryonic brain development, neuropsychiatric disorders, neurodegenerative and infectious diseases at the systems level. The National Council for Science and Technology (CONACYT), Government of Mexico, awarded me with a lifetime honorary distinction called Sistema Nacional de Investigadores nivel 1 (System of National Investigator level 1) and fellowship for three subsequent years.\nI have published several research papers, book chapters, and a book in prestigious journals from Nature, Oxford, Elsevier, Springer, BioMedCentral, PLoS, and Frontiers publication houses. Currently, I have contracts to write and edit two books. I am also an editorial board member of Frontiers and Dove Medical Press journals and review research manuscripts for over 30 journals. I have received several national and international fellowships by competition, including UGC-NET, DBT-JRF, and UGC-JRF from the Indian government, travel fellowships from the European Science Foundation, and the International Society for Computational Biologists."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Laboratory for Genomics Research!",
    "section": "",
    "text": "Our research is dedicated to delving into the multifaceted realm of gene functionality, with a specific focus on infectious, autoimmune, neurodegenerative, and neuropsychiatric diseases and disorders. Utilizing cutting-edge methodologies, we conduct in-depth analyses of extensive data to identify essential genetic modules that play pivotal roles in the genesis and progression of these conditions."
  },
  {
    "objectID": "publications.html#section",
    "href": "publications.html#section",
    "title": "Publications",
    "section": "2023",
    "text": "2023\nMuley VY*. (2023): Centrality Analysis of Protein-Protein Interaction Networks Using R, In: Mukhtar, S. (eds) Protein-Protein Interactions, Methods in Molecular Biology. 2023 Jul 15;2690:445-456\nPubMed Journal\nMuley VY*. (2023): Search, Retrieve, Visualize and Analyze Protein-Protein Interactions From Multiple Databases: A Guide to Experimental Biologists, In: Mukhtar, S. (eds) Protein-Protein Interactions, Methods in Molecular Biology. 2023 Jul 15;2690:429-443\nPubMed Journal"
  },
  {
    "objectID": "publications.html#section-1",
    "href": "publications.html#section-1",
    "title": "Publications",
    "section": "2022",
    "text": "2022\nMuley VY*, König R. (2022): Human transcriptional gene regulatory network compiled from 14 data resources, Biochimie, 2022 Feb 1;193:115-125\nPubMed Journal"
  },
  {
    "objectID": "publications.html#section-2",
    "href": "publications.html#section-2",
    "title": "Publications",
    "section": "2021",
    "text": "2021\nMuley VY*. (2021): Mathematical Linear Programming to Model MicroRNAs-Mediated Gene Regulation Using Gurobi Optimizer, In: MUKHTAR, S. (eds) Modeling Transcriptional Regulation, Methods in Molecular Biology, 2021 Jul 13;2328:287-301\nPubMed Journal\nMuley VY*. (2021): Mathematical Programming for Modeling Expression of a Gene Using Gurobi Optimizer to Identify Its Transcriptional Regulators, In: MUKHTAR, S. (eds) Modeling Transcriptional Regulation, Methods in Molecular Biology, 2021 Jul 13;2328:99-113\nPubMed Journal\nAviña-Padilla K, Ramírez-Rafael JA, Herrera-Oropeza GE, Muley VY, Valdivia DI, Díaz-Valenzuela E, García-García A, Varela-Echavarría A, Hernández-Rosales M. (2021): Evolutionary Perspective and Expression Analysis of Intronless Genes Highlight the Conservation of Their Regulatory Role, Frontiers in Genetics, 2021 Jul 9;12:654256\nPubMed Journal\nMuley VY*, Bojórquez SAF, Kamble KD. (2021): Nervous System of Invertebrates, Encyclopedia of Animal Cognition and Behavior, 2021 Mar 12: Springer, Cham\nWebLink"
  },
  {
    "objectID": "publications.html#section-3",
    "href": "publications.html#section-3",
    "title": "Publications",
    "section": "2020",
    "text": "2020\nMuley VY*, López-Victorio CJ, Ayala-Sumuano JT, González-Gallardo A, González-Santos L, Lozano-Flores C, Wray G, Hernández-Rosales M, Varela-Echavarría A. (2020): Conserved and divergent expression dynamics during early patterning of the telencephalon in mouse and chick embryos, Progress in Neurobiology, 2020 Mar 1;186:101735\nPubMed Journal"
  },
  {
    "objectID": "publications.html#section-4",
    "href": "publications.html#section-4",
    "title": "Publications",
    "section": "2019",
    "text": "2019\nMuley VY*, Larriva-Sánchez F. (2019): Nervous System, The, Encyclopedia of Animal Cognition and Behavior, 2019 Aug 29: Springer, Cham\nWebLink\nMuley VY*, Gijón CET, García IM, Cueva LX. (2019): Vertebrate Nervous System, Encyclopedia of Animal Cognition and Behavior, 2019 Jun 26: Springer, Cham\nWebLink\nMuley VY*, Akhter Y, Galande S. (2019): PDZ Domains Across the Microbial World: Molecular Link to the Proteases, Stress Response, and Protein Synthesis, Genome Biology and Evolution, 2019 Mar 1;11(3):644-659\nPubMed Journal"
  },
  {
    "objectID": "publications.html#section-5",
    "href": "publications.html#section-5",
    "title": "Publications",
    "section": "2018",
    "text": "2018\nMuley VY*, Pathania A. (2018): Gene Expression, Encyclopedia of Animal Cognition and Behavior, 2018 Oct 20: Springer, Cham\nWebLink\nJangid RK, Kelkar A, Muley VY, Galande S. (2018): Bidirectional promoters exhibit characteristic chromatin modification signature associated with transcription elongation in both sense and antisense directions, BMC Genomics, 2018 May 2;19(1):313\nPubMed Journal"
  },
  {
    "objectID": "publications.html#section-6",
    "href": "publications.html#section-6",
    "title": "Publications",
    "section": "2017",
    "text": "2017\nMuley VY*. (2017): Bioinformatics, Encyclopedia of Animal Cognition and Behavior, 2017 Sept 5: Springer, Cham\nWebLink\nPathania A, Muley VY*. (2017): Gene Expression Profiling, Encyclopedia of Animal Cognition and Behavior, 2017 Aug 22: Springer, Cham\nWebLink\nVenkatRao V, Kumar SK, Sridevi P, Muley VY, Chaitanya RK. (2017): Cloning, characterization and transmission blocking potential of midgut carboxypeptidase A in Anopheles stephensi, Acta Tropica, 2017 Apr;168:21-28\nPubMed Journal\nHaldar KK, Muley VY, Datar S, Patra A. (2017): Structural and electronic investigation of metal-semiconductor hybrid tetrapod hetero-structures, Gold Bulletin, 2017 Mar 9;50:105–110\nJournal"
  },
  {
    "objectID": "publications.html#section-7",
    "href": "publications.html#section-7",
    "title": "Publications",
    "section": "2016",
    "text": "2016\nMuley VY*, Hahn A. (2016): Protein-protein functional linkage predictions: bringing regulation to context, Computational Biology & Bioinformatics: Gene Regulation, 2016 May 12, Taylor & Francis\nWebLink\nSalah FS, Ebbinghaus M, Muley VY, Zhou Z, Al-Saadi KR, Pacyna-Gengelbach M, O’Sullivan GA, Betz H, König R, Wang ZQ, Bräuer R, Petersen I. (2016): Tumor suppression in mice lacking GABARAP, an Atg8/LC3 family member implicated in autophagy, is associated with alterations in cytokine secretion and cell death, Cell Death & Disease, 2016 Apr 28;7(4):e2205\nPubMed Journal"
  },
  {
    "objectID": "publications.html#section-8",
    "href": "publications.html#section-8",
    "title": "Publications",
    "section": "2014",
    "text": "2014\nKarmodiya K, Anamika K, Muley VY, Pradhan SJ, Bhide Y, Galande S. (2014): Camello, a novel family of Histone Acetyltransferases that acetylate histone H4 and is essential for zebrafish development, Scientific Reports, 2014 Aug 15;4:6076\nPubMed Journal"
  },
  {
    "objectID": "publications.html#section-9",
    "href": "publications.html#section-9",
    "title": "Publications",
    "section": "2013",
    "text": "2013\nMuley VY, Ranjan A. (2013): Evaluation of physical and functional protein-protein interaction prediction methods for detecting biological pathways, PLOS One, 2013 Jan 17;8(1):e54325\nPubMed Journal"
  },
  {
    "objectID": "publications.html#section-10",
    "href": "publications.html#section-10",
    "title": "Publications",
    "section": "2012",
    "text": "2012\nMuley VY, Acharya V. (2012): Genome-wide prediction and analysis of protein-protein functional linkages in bacteria, SpringerBriefs in Systems Biology, 2012 Jul 28:Volume 2, Springer Nature (ISBN 978-1-4614-4705-4), Book\nWebLink\nMuley VY, Ranjan A. (2012): Effect of reference genome selection on the performance of computational methods for genome-wide protein-protein interaction prediction, PLOS One, 2012 Jul 26;7(7):e42057\nPubMed Journal\nKamble KD, Bidwe PR, Muley VY, Kamble LH, Bhadange DG, Musaddiq M. (2012): Characterization of L-asparaginase producing bacteria from water, farm and saline soil, Bioscience discovery, 2012 Jan 1;3 (1), 116-119\nJournal\nKamble KD, More A, Muley VY. (2012): Effect of incubation on DNase production by a moderate thermophilic bacterium screened from arid land, Journal of Pure and Applied Microbiology, 2012 Mar 31;6(1):265-269\nJournal"
  },
  {
    "objectID": "publications.html#in-processpreprints-upcoming",
    "href": "publications.html#in-processpreprints-upcoming",
    "title": "Publications",
    "section": "In process/Preprints (Upcoming)",
    "text": "In process/Preprints (Upcoming)\nMuley VY*. (2023): Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R, In: Sudip Mandal (Eds): Reverse Engineering of Regulatory Networks, Methods in Molecular Biology. Vol 2719, Proof submitted, in production\nMuley VY*. (2023): Prediction and Analysis of Transcription Factor Binding Sites: Practical examples using R programming, In: Sudip Mandal (Eds): Reverse Engineering of Regulatory Networks, Methods in Molecular Biology. Vol 2719, Proof submitted, in production\nRobles-Rodríguez C, Muley VY, González-Dávalos LM, Shimada A, Varela-Echavarría A, Mora O*. (2023): Microbial colonization dynamics of the posnatal digestive tract of calves, Under Revision\nRakshit S, More A, Gaikwad S, Gade A, Seniya C, Muley VY, Mukherjee A*, Kamble K*. (2023): Role of Diosgenin in suppression of HIV-1 replication: An in vitro preclinical study, Submitted\nMuley VY*, Singh A, Gruber K, Kamble KD, Varela-Echavarría A. (2023): Potential functions of the amino-terminal cytoplasmic region of SARS-CoV-2 entry protein TMPRSS2 in virion assembly and early secretory pathway, In preparation, A part of this work is available as a preprint at BioRxiv\nPreprint"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "aboutVijay.html",
    "href": "aboutVijay.html",
    "title": "Laboratory for Genomics Research!",
    "section": "",
    "text": "I specialize in the cutting-edge field of computational biology, utilizing my expertise in bioinformatics and data science to uncover the mysteries of molecular biology, microbiology, neurobiology, immunology, evolution, and developmental biology. With a wealth of experience working in government and public universities in India, Germany, Ireland, and Mexico, I have a deep understanding of the advanced computational methods required to study the intricate inner workings of living organisms, cells, subcellular structures, genes, proteins, and their interactions.\nI received my B.Sc. degree in Chemistry, Zoology, and Fishery Science in 2000 and my M.Sc. in Biotechnology in 2002 from Dr. Babasaheb Ambedkar Marathwada University in Aurangabad, India. In 2005, I completed my second M.Sc. degree in Bioinformatics at the University of Pune in Pune, India. In 2012, I obtained my Ph.D. degree in Bioinformatics from the Computational and Functional Genomics Laboratory at the Centre for Fingerprinting and DNA Diagnostics (CDFD) in Hyderabad, India, under the supervision of Dr. Akash Ranjan.\nIn April 2012, I joined the Indian Institute of Science Education and Research (IISER) in Pune, India as a postdoctoral scientist in Dr. Sanjeev Galande’s laboratory, where I worked on animal evolution, embryonic development, and epigenetic regulation. In October 2013, I moved to Jena, Germany as a staff scientist and worked on mathematical modeling of gene expression and regulation in breast cancers at the Leibniz Institute for Natural Product Research and Infection Biology, in the Network Modelling group headed by Professor Rainer Koenig. In February 2016, I was appointed as an assistant professor on a permanent basis at the Central University of Punjab in Bathinda, India in the Centre for Computational Sciences. However, I resigned from the position after a while and decided to work as a full-time researcher at University College Cork, National University of Ireland in Cork City, Ireland from September 2017. There, I worked on IFN-gamma and TNF-alpha signaling pathways involved in immune responses with Dr. Ken Nally. In April 2018, I was invited to join the Institute of Neurobiology at the National Autonomous University of Mexico (UNAM) in Queretaro, Mexico, as an assistant professor and senior scientist in the neural laboratory of neural development. At UNAM, I worked on various research projects in the field of neurobiology and studied the molecular basis of embryonic brain development, neuropsychiatric disorders, neurodegenerative and infectious diseases at the systems level. The National Council for Science and Technology (CONACYT), Government of Mexico, awarded me with a lifetime honorary distinction called Sistema Nacional de Investigadores nivel 1 (System of National Investigator level 1) and fellowship for three subsequent years.\nIf you share my passion for using science and data to improve productivity and living standards, I would love to hear from you. Whether you are interested in research, internships, collaboration, or consultancy, please don’t hesitate to contact me via the social media links provided. I am always open to discussing new opportunities and exciting projects."
  },
  {
    "objectID": "cvVijay.html",
    "href": "cvVijay.html",
    "title": "Curriculum vitae",
    "section": "",
    "text": "Apr 2018 – Nov 2022 | Assistant Professor |\nInstitute of Neurobiology, National Autonomous University of Mexico (UNAM), Queretaro, Mexico\nSep 2017 – Apr 2018 | Post-doctoral Researcher |\nAPC Microbiome, University College Cork, National University of Ireland, Cork, Ireland\nFeb 2016 – Apr 2017 | Assistant Professor |\nCentre for Computational Sciences, Central University of Punjab, Bathinda, India\nOct 2013 – Dec 2015 | Post-doctoral Researcher |\nLeibniz Institute for Natural Product Research and Infection Biology - Hans-Knöll-Institut, Jena, Germany\nApr 2012 – Aug 2013 | Post-doctoral Researcher |\nCentre for Excellence in Epigenetics, Indian Institute of Science, Education and Research, Pune, India"
  },
  {
    "objectID": "cvVijay.html#education",
    "href": "cvVijay.html#education",
    "title": "Curriculum vitae",
    "section": "Education",
    "text": "Education\n2005-2012 | Ph.D. Bioinformatics | Centre for DNA Fingerprinting and Diagnostics, India\n2003-2005 | M.Sc. Bioinformatics | Savitribai Phule Pune University, India\n2000-2002 | M.Sc. Biotechnology | Dr. Babasaheb Ambedkar Marathwada University, India\n1997-2000 | Bachelor of Science | Dr. Babasaheb Ambedkar Marathwada University, India"
  },
  {
    "objectID": "cvVijay.html#honours-awards-and-fellowships",
    "href": "cvVijay.html#honours-awards-and-fellowships",
    "title": "Curriculum vitae",
    "section": "Honours, awards and fellowships",
    "text": "Honours, awards and fellowships\nJan 2020 - Nov 2022 | Sistema Nacional de Investigadores Nivel I (National System of Investigators) |\nHonorary distinction and fellowship from National Council for Science and Technology (CONACyT), Government of Mexico\nSep 2010 | Travel fellowship to Belgium | International Society for Computational Biology\nApr 2010 | Travel fellowship to Germany, | European Science Foundation\nApr 2010 | Best poster presentation | 4th ESF conference on Functional Genomics and Diseases, Germany\nSep 2005 - Sep 2010 | Junior Research Fellowship | Department of Biotechnology, Government of India\nDec 2005 - Dec 2010 | Junior Research Fellowship | University Grant Commission, Government of India, Not availed\nJun 2004 - Lifetime | National Eligibility Test for Lectureship | University Grant Commission, Government of India"
  },
  {
    "objectID": "cvVijay.html#research-grants-and-projects",
    "href": "cvVijay.html#research-grants-and-projects",
    "title": "Curriculum vitae",
    "section": "Research grants and projects",
    "text": "Research grants and projects\n1 Jan 2020 – 31 Dec 2021 | Principal Investigator |\nIdentification of brain-specific cell death genetic modules and their relevance in neurodegeneration\nFunded by General Directorate for Academic Personnel Affairs, National Autonomous University of México, Mexico\n1 Jan 2011 – 31 Dec 2013 | Co-investigator | Genetic diversity and first generation linkage map of Clarias batrachus | Funded by Department of Biotechnology, Government of India, India"
  },
  {
    "objectID": "cvVijay.html#software-and-database-developed",
    "href": "cvVijay.html#software-and-database-developed",
    "title": "Curriculum vitae",
    "section": "Software and database developed",
    "text": "Software and database developed\nNeurodegenerative Disease Gene Expression database (NDGEx) : A database of differential expression results in 25 neurodegenerative diseases from 155 independent microarray datasets\nCell Death and Survival gene database (CDSG) : A database of 8,380 predicted genes from 175 species linked with literature on cell death and survival\nEscherichia coli functional protein-protein interactions (EcoFunPPI) : A database of functional protein-protein interactions in Escherichia coli K12 predicted using a combination of 9 machine learning methods\npub2path : R package to reconstruct biological pathway or process of your interest without a prior knowledge of gene functions from PubMed literature. Access will be given on request since its in final stage of development. For example, above- mentioned CDSG database created using pub2path."
  },
  {
    "objectID": "cvVijay.html#invited-talks",
    "href": "cvVijay.html#invited-talks",
    "title": "Curriculum vitae",
    "section": "Invited talks",
    "text": "Invited talks\n2 Jan 2023 | Probing TMPRSS2 and ACE2 SARS-CoV-2 cell entry receptors to reveal COVID-19 pathogenesis and potential drug targets at the International Conference on Drug Development and Drug Discovery, Swami Ramanand Teerth Marathwada University, Nanded, India\n16 Apr 2021 | Cross-species transcriptomic analysis of SARS-CoV-2 cell entry receptors reveal potential targets at the Institute of Neurobiology, National Autonomous University of Mexico, Queretaro, Mexico\n16 Jun 2018 | Differential Expression Analysis using R at the III interactional Summer School in Bioinformatics, Institute of Mathematics, National Autonomous University of Mexico, Queretaro, Mexico"
  },
  {
    "objectID": "cvVijay.html#publications",
    "href": "cvVijay.html#publications",
    "title": "Curriculum vitae",
    "section": "Publications",
    "text": "Publications"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Page under construction"
  },
  {
    "objectID": "resources.html#publications-to-pathway-mapping-pub2path",
    "href": "resources.html#publications-to-pathway-mapping-pub2path",
    "title": "Resources",
    "section": "Publications to Pathway mapping (pub2path)",
    "text": "Publications to Pathway mapping (pub2path)\npub2path is a R package to reconstruct biological pathway or process of your interest without a prior knowledge of gene functions from PubMed literature. Access will be given on request since pub2path manuscript is under preparation. CDSG database (see below) was created using pub2path results."
  },
  {
    "objectID": "resources.html#neurodegenerative-disease-gene-expression-database-ndgex",
    "href": "resources.html#neurodegenerative-disease-gene-expression-database-ndgex",
    "title": "Resources",
    "section": "Neurodegenerative Disease Gene Expression database (NDGEx)",
    "text": "Neurodegenerative Disease Gene Expression database (NDGEx)\nNDGEx is a database of differential expression results in 25 neurodegenerative diseases from 155 independent microarray datasets."
  },
  {
    "objectID": "resources.html#cell-death-and-survival-gene-database-cdsg",
    "href": "resources.html#cell-death-and-survival-gene-database-cdsg",
    "title": "Resources",
    "section": "Cell Death and Survival gene database (CDSG)",
    "text": "Cell Death and Survival gene database (CDSG)\nCDSG ia a database of 8,380 predicted genes from 175 species linked with literature pub2path algorithm (unpublished) on cell death and survival."
  },
  {
    "objectID": "resources.html#escherichia-coli-functional-protein-protein-interactions-ecofunppi",
    "href": "resources.html#escherichia-coli-functional-protein-protein-interactions-ecofunppi",
    "title": "Resources",
    "section": "Escherichia coli functional protein-protein interactions (EcoFunPPI)",
    "text": "Escherichia coli functional protein-protein interactions (EcoFunPPI)\nEcofunPPI ia a database of functional protein-protein interactions in Escherichia coli K12 predicted using a combination of 9 machine learning methods. It is highly reliable database than several existing published database on PPI and could provide a experimentally testable hypothesis on proteins of interest."
  },
  {
    "objectID": "protocols.html",
    "href": "protocols.html",
    "title": "Protocols",
    "section": "",
    "text": "Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R\n\n\nTranscriptional regulatory network predictions\n\n\n\n\n\n\nVijaykumar Yogesh Muley\n\n\n23 min\n\n\n\n\n\n\nNo matching items"
  }
]