{
  "hash": "4f8d4688aa41aa7f60733333243fc09b",
  "result": {
    "markdown": "---\ntitle: \"Deep Learning for Predicting Gene Regulatory Networks: A Step-by-Step Protocol in R\"\nsubtitle: Transcriptional regulatory network predictions\nauthor:\n  - name: Vijaykumar Yogesh Muley\ncategories: [Deep learning, GRN] # self-defined categories\ncitation:\n  type: article-journal\n  container-title: Methods in Molecular Biology\n  volume: 2719\n#  issue: 2\n  issued: 2023-08\n#  issn: 1539-9087\n#  url: https://doi.org/10.1007/978-1-0716-3461-5_15 \n#image: preview_image.jpg\ndraft: false \n---\n\n\n## Computational and software requirements\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"tensorflow\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\npath_to_python <- \"/usr/local/bin/python3\" \nvirtualenv_create(\"r-reticulate\", python = path_to_python)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\npath_to_python <- \"/usr/local/bin/python3\" \nvirtualenv_create(\"r-reticulate\", python = path_to_python)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tensorflow)\ninstall_tensorflow(envname = \"r-reticulate\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"keras\")\nlibrary(keras)\ninstall_keras(envname = \"r-reticulate\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tensorflow)\ntf$constant(\"Hello Tensorflow!\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(c(\"readr\", \"tibble\", \"caret\", \"verification\"))\n```\n:::\n\n\n\n# Methods\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(magrittr)\nlibrary(keras)\nlibrary(tensorflow)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1979)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexp <- read.table(\"net3_expression_data.tsv\", header = T)\nexp <- t(exp)\ndim(exp)\nexp[1:5,1:5]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot\nhist(exp, 100, col = \"darkgrey\", border = \"white\", \n     xlab = \"Expression intensity\", main = \"Gene expression\")\n\n# export plot to pdf file in the current directory\npdf(file = \"DeepLearning_Figure1.pdf\", \n    width = 5, height = 5, pointsize = 10, useDingbats = FALSE)\nhist(exp, 100, col = \"darkgrey\", border = \"white\", \n     xlab = \"Expression intensity\", main = \"Gene expression\")\ndev.off()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngold <- readr::read_table(\"DREAM5_NetworkInference_GoldStandard_Network3.tsv\",\n                          col_names = F)\ngold\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngold <- gold[gold$X1 %in% rownames(exp) & gold$X2 %in% rownames(exp), ]\ntable(gold$X3)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkeep_indices <- c(which(gold$X3==1), \n                  sample(which(gold$X3==0), size = sum(gold$X3)*2))\ngold <- gold[keep_indices,]\ntable(gold$X3)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ninputdata <- data.frame(tf = gold$X1, gene = gold$X2, \n                        exp[gold$X1,], exp[gold$X2,])\ninputdata$pcc <- sapply(seq.int(dim(gold)[1]), function(i) \n                        cor(exp[gold$X1[i],], exp[gold$X2[i],]))\ninputdata$class <- gold$X3\n\ninputdata <- tibble::as_tibble(inputdata)\n\nfeaturenames <- colnames(inputdata) %>% setdiff(\"class\")  %>% \n  setdiff(\"tf\") %>% setdiff(\"gene\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nh1 <- hist(as.matrix(inputdata[inputdata$class==\"1\",featurenames]), \n           breaks = 100, plot = FALSE)\nh2 <- hist(as.matrix(inputdata[inputdata$class==\"0\",featurenames]), \n           breaks = 100, plot = FALSE)\n\npdf(file = \"DeepLearning_Figure2.pdf\", \n    width = 5, height = 5, pointsize = 10, useDingbats = FALSE)\nplot(h2, col = rgb(0,0,1,0.4), freq = FALSE, \n     xlab = \"Expression intensity\", \n     main = \"Distribution of feature values for training data\")\nplot(h1, xaxt = \"n\", yaxt = \"n\", col = rgb(1,0,0,0.4), \n     freq = FALSE, add = TRUE)\ndev.off()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nindices <- nrow(inputdata) %>% sample.int(., ceiling( . * 0.8))\ntraindata <- inputdata[indices, ]\ntestdata <- inputdata[-indices, ]\nindices <- nrow(testdata) %>% sample.int(., ceiling( . * 0.5))\nvaldata <- testdata[-indices, ]\ntestdata <- testdata[indices, ]\ntable(traindata$class)\ntable(valdata$class)\ntable(testdata$class)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset_random_seed(1979)\n\nmodel <- keras_model_sequential(\n  input_shape = c(length(featurenames))) %>%\n  layer_dense(units = 806, activation = \"relu\") %>%\n  layer_dense(units = 1, activation = \"sigmoid\")\n\nsummary(model)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel %>% compile(optimizer = optimizer_adam(),\n loss = \"binary_crossentropy\",\n metrics = c(\"accuracy\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhistory <- model %>% fit(as.matrix(traindata[,featurenames]), \n                         traindata$class,\n                         epochs=100, batch_size = 64,\n                         validation_data = list(as.matrix(valdata[,featurenames]), \n                                                valdata$class))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(history)\nevaluate(model, x = as.matrix(traindata[,featurenames]), y = traindata$class)\nevaluate(model, x = as.matrix(valdata[,featurenames]), y = valdata$class)\nplot(history)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npdf(file = \"DeepLearning_Figure3.pdf\",\n    width = 7, height = 4, pointsize = 10, useDingbats = FALSE)\n\npar(mfrow = c(1,2), cex = 0.8)\n\nmaxLoss <- max(c(history$metrics$loss, history$metrics$val_loss))\n\nplot(history$metrics$loss, main=\"Model Loss\", xlab = \"Epoch\", ylab=\"Loss\", \n     xlim = c(0, length(history$metrics$loss)), ylim = c(0, maxLoss),\n     col=\"red2\", type=\"b\",lwd=1)\nlines(history$metrics$val_loss, col=\"steelblue1\", type=\"b\",lwd=1)\nlegend(\"topright\", c(\"Training\",\"Validation\"), col=c(\"red2\", \"steelblue1\"), \n       lty=c(1,1), bty = \"n\")\n\nplot(history$metrics$accuracy, col=\"red2\", type=\"b\",lwd=1, \n     main=\"Model Accuracy\", xlab = \"Epoch\", ylab=\"Accuracy\", \n     xlim = c(0, length(history$metrics$accuracy)), ylim = c(0, 1))\nlines(history$metrics$val_accuracy, col=\"steelblue1\", type=\"b\",lwd=1)\nabline(h = 0.5, col = \"grey\", lty = 3)\ndev.off()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npredprob <- model %>% predict(as.matrix(testdata[,featurenames]))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nf1 <- function(indata, truelabels){\n  res <-  model %>% predict(as.matrix(indata[,featurenames]))\n  res <- as.numeric(res>0.5)\n  res <- factor(res, c(1,0))\n  caret::confusionMatrix(res, factor(truelabels, c(1,0)))\n}\n\ntrainAccuracy <- f1(traindata, traindata$class)\nvalidationAccuracy <- f1(valdata, valdata$class)\ntestAccuracy <-f1(testdata, testdata$class)\n\nperformance <- round(t(as.data.frame(rbind(t(trainAccuracy$byClass), \n                                           t(validationAccuracy$byClass), \n                                           t(testAccuracy$byClass)))),3)\ncolnames(performance) <- c(\"Traning\", \"Validation\", \"Test\")\n\nperformance\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npdf(file = \"DeepLearning_Figure4.pdf\",\n    width = 5, height = 5, pointsize = 12, useDingbats = FALSE)\n\nverification::roc.plot(testdata$class, predprob, \n                       ylab = \"True Positive Rate\", \n                       xlab = \"False Positive Rate\")\nabline(v = 0.5596, col = \"red2\", lty = 3)\nabline(h = 0.0509, col = \"steelblue1\", lty = 3)\n\ndev.off()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsave_model_hdf5(model, \"EcoliRegModel.h5\")\nsave(exp, performance, gold, history, file = \"EcoliRegModel.RData\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(magrittr)\nlibrary(keras)\nlibrary(tensorflow)\n\nset.seed(1979)\n\n\nmodel <- load_model_hdf5(\"EcoliRegModel.h5\")\n\n# import expression data file\nexp <- t(read.table(\"net3_expression_data.tsv\", header = T))\n\n# import original gene names mapping \ngenenames <- read.table(\"net3_gene_ids.tsv\", header = F)\ngenes <- genenames$V2; names(genes) <- genenames$V1\n\n# import list of all transcription factors of Escherichia coli\n# tfs <- names(genes)[genes %in% c(\"gadX\", \"flhC\", \"flhD\",\"dnaA\")] # trail run\ntfs <- read.table(\"net3_transcription_factors.tsv\", header = F)$V1\n\nlength(tfs)*nrow(exp)\n\n\npredictions <- NULL\n\nfor(i in tfs){\n  \n  tfdata <-data.frame(tf = i, gene = rownames(exp), \n                      tfname = genes[i],\n                      genename = genes[rownames(exp)])\n  tfdata <- tibble::as_tibble(tfdata[tfdata$tf != tfdata$gene,])\n  \n  inpreddata <- cbind(exp[tfdata$tf,], exp[tfdata$gene,])\n  inpreddata <- cbind(inpreddata, \n                      sapply(seq.int(dim(tfdata)[1]), \n                             function(i) \n                               cor(exp[tfdata$tf[i],], \n                                   exp[tfdata$gene[i],])))\n  \n  tfdata$probability <- (model %>% predict(inpreddata))[,1]\n  \n  predictions <- rbind(predictions, tfdata[tfdata$probability>0.5,])\n  \n}\n\npredictions <- predictions[rev(order(predictions$probability)),]\npredictions\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions[predictions$tfname==\"gadX\",]\npredictions[predictions$tfname==\"flhC\",]\npredictions[predictions$tfname==\"flhD\",]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions[!paste0(predictions$tf,predictions$gene) %in%  \n              paste0(inputdata$tf[inputdata$class==1], \n                     inputdata$gene[inputdata$class==1]),] \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.table(predictions, file = \"grnPredictionsEcoli.txt\", \n            col.names = T, row.names = F, quote = F, sep = \"\\t\")\nwrite.csv(predictions, file = \"grnPredictionsEcoli.csv\", row.names = F)\nwritexl::write_xlsx(list(Table1 = predictions), \n                    path = \"grnPredictionsEcoli.xlsx\", col_names = T, )\n```\n:::\n\n\n\n## Handiling imbalanced gold standard data \n\n\n\n::: {.cell}\n\n:::\n\n\n## Increasing generalization and depth of DNN\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## Performance measures\n\n\n\n::: {.cell}\n\n:::\n\n\n## An alternative code for prediction of GRN on high-end computational resources.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(magrittr)\nlibrary(keras)\nlibrary(tensorflow)\n\nset.seed(1979)\n\n\nmodel <- load_model_hdf5(\"EcoliRegModel.h5\")\n\n# import expression data file\nexp <- t(read.table(\"net3_expression_data.tsv\", header = T))\n\n# import original gene names mapping \ngenenames <- read.table(\"net3_gene_ids.tsv\", header = F)\ngenes <- genenames$V2; names(genes) <- genenames$V1\n\n# import list of all transcription factors of Escherichia coli\ntfs <- read.table(\"net3_transcription_factors.tsv\", header = F)$V1\n\n# create all possible pairs between tanscription factors and genes\n\npredictions <- expand.grid(tfs,  rownames(exp), stringsAsFactors = FALSE)\npredictions <- tibble::as_tibble(all_pairs[predictions$Var1 != predictions$Var2,])\n\n# add original gene names\n\npredictions$tfname <- genes[predictions$Var1]\npredictions$genename <- genes[predictions$Var2]\n\n# create feature table\ninpreddata <- cbind(exp[predictions$Var1,], exp[predictions$Var2,])\ninpreddata$pcc  <- sapply(seq.int(dim(predictions)[1]), \n                          function(i) cor(exp[predictions$Var1[i],], \n                                          exp[predictions$Var2[i],])))\n\n# predict regulatory pairs\npredictions$probability <- (model %>% predict(inpreddata))[,1]\npredictions <- predictions[predictions$probability>0.5,]\npredictions <- predictions[rev(order(predictions$probability)),]\npredictions \n```\n:::\n\n\n\n## Controlling DNN model training by Callback functions\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nearly_stopping <- callback_early_stopping(monitor = \"val_loss\", patience = 3)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_checkpoint <- callback_model_checkpoint(filepath = \"best_model.h5\", \n                                              monitor = \"val_accuracy\", \n                                              save_best_only = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nreduce_lr <- callback_reduce_lr_on_plateau(monitor = \"val_loss\", \n                                           factor = 0.1, patience = 2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntensorboard <- callback_tensorboard(log_dir = \"logs\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhistory <- model %>% fit(as.matrix(traindata[,featurenames]), traindata$class,\n                           epochs=40, batch_size = 50, validation_split=0.2,\n                           callbacks = list(early_stopping, reduce_lr))\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}